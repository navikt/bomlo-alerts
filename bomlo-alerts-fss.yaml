apiVersion: "nais.io/v1"
kind: "Alert"
metadata:
  name: bomlo-alerts
  namespace: tbd
  labels:
    team: tbd
spec:
  receivers:
    slack:
      channel: '#team-bømlo-ops'
      prependText: '<!subteam^S010U3KQ8LQ|redteam> - '
      send_resolved: true
      username: 'En bot'
      icon_emoji: ':naiser:'
  route:
    repeat_interval: 3h
  alerts:
    - alert: errorRate
      expr: (100 * sum by (log_app) (rate(logd_messages_total{log_team="tbd",log_level="Error", log_app!="speil"}[5m])) / sum by (log_app) (rate(logd_messages_total{log_team="tbd", log_app!="speil"}[5m]))) > 10
      for: 5m
      description: "Høy feilrate: {{  $value | printf \"%.1f\" }} % i {{ $labels.log_app }} "
      action: "Sjekk logger"
      severity: danger
    - alert: appDown
      expr: max(up{team="tbd",app!="speil",job="kubernetes-pods"}) by (app) == 0
      for: 10m
      description: "{{ $labels.app }} er nede"
      action: "Sjekk logger"
      severity: warning
    - alert: speilDown
      expr: up{team="tbd",app="speil",job="kubernetes-pods"} == 0
      for: 2m
      description: "Speil er nede"
      action: "Sjekk logger"
      severity: danger
    - alert: httpErrors
      severity: danger
      expr: 100 * sum(rate(traefik_backend_requests_total{code!~"^[23].*", backend=~"speil.nais.adeo.no/"}[5m])) by (backend) /  sum(rate(traefik_backend_requests_total{backend=~"speil.nais.adeo.no/"}[5m])) by (backend) > 20
      for: 2m
      description: "{{ $labels.backend }} gir mange HTTP feilresponser"
      action: "Sjekk logger"
    - alert: Lengre enn 26 timer siden forrige avstemmingsjobb ble fullført
      severity: danger
      expr: (time() - avstemming) > 93600
      for: 3m
      action: "Sjekk logger og kubectl describe cronjob spenn-avstemming i prod-fss/tbd"
    - alert: Nedgang i utbetalinger siden forrige uke er mer enn 100 pr time
      severity: warning
      expr: sum(increase(vedtaksperiode_tilstander_totals{tilstand="TIL_UTBETALING"}[1h] )) - sum(increase(vedtaksperiode_tilstander_totals{tilstand="TIL_UTBETALING"}[1h] offset 1w)) < -100
      for: 15m
      action: "Sjekke logger i spenn"
    - alert: Godkjenningsgrad er over 10 %-poeng lavere en samme tid forrige uke
      severity: warning
      expr: ((avg_over_time(sum(vedtaksperiode_tilstander_totals{tilstand="AVVENTER_GODKJENNING",harVedtaksperiodeWarnings="0" } offset 1w) [1d:1h]) /avg_over_time(sum(vedtaksperiode_tilstander_totals{tilstand="AVVENTER_GODKJENNING" } offset 1w) [1d:1h]) )- (avg_over_time(sum(vedtaksperiode_tilstander_totals{tilstand="AVVENTER_GODKJENNING",harVedtaksperiodeWarnings="0" } ) [1d:1h]) /avg_over_time(sum(vedtaksperiode_tilstander_totals{tilstand="AVVENTER_GODKJENNING" } ) [1d:1h])) )< -0.1
      for: 15m
      action: "Sjekke logger i spleis og spesialist"
    - alert: Innkommende meldinger, differanse fra samme tid forrige uke
      severity: warning
      expr: sum(increase(melding_unik_totals{app="spedisjon"}[1h])) by (type) - sum(increase(melding_unik_totals{app="spedisjon"}[1h] offset 1w)) by (type) <-200
      for: 30m
      description: "Det kommer færre meldinger av type {{ $labels.type }} enn forrige uke"
      action: "Sjekke logger i spedisjon"



